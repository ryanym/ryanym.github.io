<!DOCTYPE html>
<html lang="en"><meta charset="utf-8"><meta name="generator" content="Hugo 0.62.0" /><meta name="viewport" content="width=device-width,initial-scale=1,viewport-fit=cover">
<meta name="color-scheme" content="light dark">
<meta name="supported-color-schemes" content="light dark"><title>Accessing mutiple Hadoop amespaces with native HDFS client&nbsp;&ndash;&nbsp;Untitled Thoughts</title><link rel="stylesheet" href="/css/core.min.8c24852e5f6a6bd910400b8fbb878613fcb4debd54b64e9c0e3309c16ff60dd7c9fb88e29ad2fbefeb14054f849ce8ad.css" integrity="sha384-jCSFLl9qa9kQQAuPu4eGE/y03r1Utk6cDjMJwW/2DdfJ&#43;4jimtL77&#43;sUBU&#43;EnOit"><meta name="twitter:card" content="summary" />
<meta name="twitter:title" content="Accessing mutiple Hadoop amespaces with native HDFS client" />

<link rel="shortcut icon" type="image/x-icon" href="https://ryanym.com/favicon.ico">
<body><section id="header">
    <div class="header wrap"><span class="header left-side"><a class="site home" href="/"><span class="site name">Untitled Thoughts</span></a></span>
        <span class="header right-side"><div class="nav wrap"><nav class="nav"><a class="nav item" href="/categories/">Categories</a><a class="nav item" href="/tags/">Tags</a><a class="nav item" href="/coursework">Coursework</a><a class="nav item" href="/bookshelf/">Bookshelf</a></nav></div></span></div></section><section id="content"><div class="article-container"><section class="article header">
    <h1 class="article title">Accessing mutiple Hadoop amespaces with native HDFS client</h1><p class="article date">Wednesday, February 5, 2020</p></section><article class="article markdown-body"><p>In hadoop we can have multiple namespaces in <code>hdfs-site.xml</code> for HDFS clients. This is achieved by a HDFS feature called: <a href="https://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-hdfs/Federation.html"target="_blank">HDFS Federation</a></p>
<h3 id="why-do-you-need-multiple-namespaces">Why do you need multiple namespaces</h3>
<p>This feature is particularly useful when you need to distcp data between multiple highly available remote hadoop clusters. For HA clusters we don't always know the address of active namenode and it's not recommanded to hardcode the active namenode address in the distcp command in case of namenode fail over.</p>
<h3 id="how-to-add-additional-namespaces">How to add additional namespaces</h3>
<p>Cloudera has a detailed <a href="https://docs.cloudera.com/documentation/enterprise/5-14-x/topics/cdh_admin_distcp_data_cluster_migrate.html#distcp_ha"target="_blank">document</a> on how to setup distcp with HA remote clusters. In essence, you need to edit <code>dfs.nameservices</code> property and add the following properties to <code>hdfs-site.xml</code>. (I have prepared a <a href="https://gist.github.com/ryanym/eb3618efd2572d0b97c962b6be57d6bf"target="_blank">script</a> to generate below content, it assumes all services are in their default ports)</p>
<p>Edit:</p>
<p>Note the order of the nameservices matters, the first nameservice will be the default hdfs namespace that you can access without the <code>hdfs://</code> URI</p>
<pre><code>&lt;property&gt;
 &lt;name&gt;dfs.nameservices&lt;/name&gt;
 &lt;value&gt;nameservice1,pdvnameservice&lt;/value&gt;
&lt;/property&gt;
</code></pre><p>Add:</p>
<pre><code>  &lt;property&gt;
    &lt;name&gt;dfs.ha.namenodes.pdvnameservice&lt;/name&gt;
    &lt;value&gt;namenode1,namenode2&lt;/value&gt;
  &lt;/property&gt;
  &lt;property&gt;
    &lt;name&gt;dfs.client.failover.proxy.provider.pdvnameservice&lt;/name&gt;
    &lt;value&gt;org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider&lt;/value&gt;
  &lt;/property&gt;
  &lt;property&gt;
    &lt;name&gt;dfs.ha.automatic-failover.enabled.pdvnameservice&lt;/name&gt;
    &lt;value&gt;true&lt;/value&gt;
  &lt;/property&gt;
  &lt;property&gt;
    &lt;name&gt;dfs.namenode.rpc-address.pdvnameservice.namenode1&lt;/name&gt;
    &lt;value&gt;master1.example.com:8020&lt;/value&gt;
  &lt;/property&gt;
  &lt;property&gt;
    &lt;name&gt;dfs.namenode.rpc-address.pdvnameservice.namenode2&lt;/name&gt;
    &lt;value&gt;master2.example.com:8020&lt;/value&gt;
  &lt;/property&gt;
  &lt;property&gt;
    &lt;name&gt;dfs.namenode.servicerpc-address.pdvnameservice.namenode1&lt;/name&gt;
    &lt;value&gt;master1.example.com:8022&lt;/value&gt;
  &lt;/property&gt;
  &lt;property&gt;
    &lt;name&gt;dfs.namenode.servicerpc-address.pdvnameservice.namenode2&lt;/name&gt;
    &lt;value&gt;master2.example.com:8022&lt;/value&gt;
  &lt;/property&gt;
  &lt;property&gt;
    &lt;name&gt;dfs.namenode.http-address.pdvnameservice.namenode1&lt;/name&gt;
    &lt;value&gt;master1.example.com:50070&lt;/value&gt;
  &lt;/property&gt;
  &lt;property&gt;
    &lt;name&gt;dfs.namenode.http-address.pdvnameservice.namenode2&lt;/name&gt;
    &lt;value&gt;master2.example.com:50070&lt;/value&gt;
  &lt;/property&gt;
  &lt;property&gt;
    &lt;name&gt;dfs.namenode.https-address.pdvnameservice.namenode1&lt;/name&gt;
    &lt;value&gt;master1.example.com:50470&lt;/value&gt;
  &lt;/property&gt;
  &lt;property&gt;
    &lt;name&gt;dfs.namenode.https-address.pdvnameservice.namenode2&lt;/name&gt;
    &lt;value&gt;master2.example.com:50470&lt;/value&gt;
  &lt;/property&gt;
  &lt;property&gt;
    &lt;name&gt;dfs.namenode.rpc-address.pdvnameservice.namenode1&lt;/name&gt;
    &lt;value&gt;master1.example.com:8020&lt;/value&gt;
  &lt;/property&gt;
  &lt;property&gt;
    &lt;name&gt;dfs.namenode.rpc-address.pdvnameservice.namenode2&lt;/name&gt;
    &lt;value&gt;master2.example.com:8020&lt;/value&gt;
  &lt;/property&gt;
  &lt;property&gt;
    &lt;name&gt;dfs.namenode.servicerpc-address.pdvnameservice.namenode1&lt;/name&gt;
    &lt;value&gt;master1.example.com:8022&lt;/value&gt;
  &lt;/property&gt;
  &lt;property&gt;
    &lt;name&gt;dfs.namenode.servicerpc-address.pdvnameservice.namenode2&lt;/name&gt;
    &lt;value&gt;master2.example.com:8022&lt;/value&gt;
  &lt;/property&gt;
  &lt;property&gt;
    &lt;name&gt;dfs.namenode.http-address.pdvnameservice.namenode1&lt;/name&gt;
    &lt;value&gt;master1.example.com:50070&lt;/value&gt;
  &lt;/property&gt;
  &lt;property&gt;
    &lt;name&gt;dfs.namenode.http-address.pdvnameservice.namenode2&lt;/name&gt;
    &lt;value&gt;master2.example.com:50070&lt;/value&gt;
  &lt;/property&gt;
  &lt;property&gt;
    &lt;name&gt;dfs.namenode.https-address.pdvnameservice.namenode1&lt;/name&gt;
    &lt;value&gt;master1.example.com:50470&lt;/value&gt;
  &lt;/property&gt;
  &lt;property&gt;
    &lt;name&gt;dfs.namenode.https-address.pdvnameservice.namenode2&lt;/name&gt;
    &lt;value&gt;master2.example.com:50470&lt;/value&gt;
  &lt;/property&gt;
</code></pre><h3 id="test-the-added-namespace">Test the added namespace</h3>
<div class="highlight"><pre class="chroma"><code class="language-bash" data-lang="bash">hdfs --config ~/hadoop-conf-editted dfs -ls hdfs://addednameservice/                   
Found <span class="m">13</span> items
drwx------+  - hbase        hbase                 <span class="m">0</span> 2020-02-04 15:25 hdfs://addednameservice/hbase
drwxrwxr-x+  - hdfs         supergroup            <span class="m">0</span> 2019-05-02 14:29 hdfs://addednameservice/share
drwxrwxrwt+  - hdfs         supergroup            <span class="m">0</span> 2019-08-22 20:42 hdfs://addednameservice/tmp
drwxrwxr-x+  - hdfs         supergroup            <span class="m">0</span> 2020-02-04 16:32 hdfs://addednameservice/user

</code></pre></div><h3 id="pushing-changes-to-all-clients-from-cloudera-manager">Pushing changes to all clients from Cloudera Manager</h3>
<p><code>HDFS</code> -&gt; <code>Configuration</code> -&gt; <code>Scope: Gateway</code> -&gt;<code>HDFS Client Advanced Configuration Snippet (Safety Valve) for hdfs-site.xml</code></p>
<p>Choose <code>View as XML</code> and copy the above properties. Note this will trigger a cluster restart and client configuration deploy.</p>
<p>Once changes are pushed to clients, we can now access the added namespace without the customised <code>hdfs-site.xml</code></p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">hdfs dfs -ls hdfs://addednameservice/                   
Found <span class="m">13</span> items
drwx------+  - hbase        hbase                 <span class="m">0</span> 2020-02-04 15:25 hdfs://addednameservice/hbase
drwxrwxr-x+  - hdfs         supergroup            <span class="m">0</span> 2019-05-02 14:29 hdfs://addednameservice/share
drwxrwxrwt+  - hdfs         supergroup            <span class="m">0</span> 2019-08-22 20:42 hdfs://addednameservice/tmp
drwxrwxr-x+  - hdfs         supergroup            <span class="m">0</span> 2020-02-04 16:32 hdfs://addednameservice/user
</code></pre></div><h3 id="going-to-hdfs-federation">Going to HDFS Federation</h3>
<p>If you are using Cloudera distribution of hadoop this can be done in Cloudera Manager using <a href="https://docs.cloudera.com/documentation/enterprise/5-14-x/topics/cdh_admin_distcp_data_cluster_migrate.html#distcp_ha"target="_blank">Add Nameservice</a></p>
<p>Note that HDFS Federation is <strong>not</strong> supported in CDH 6 or CDP</p>
</article><section class="article labels"><a class="category" href=/categories/bigdata/>bigdata</a><a class="tag" href=/tags/hadoop/>hadoop</a></section></div>
<div class="article bottom"><section class="article navigation"><p><a class="link" href="/posts/leetcode-lru-cache/"><span class="li iconfont icon-article"></span>Implement LRU Cache</a></p><p><a class="link" href="/posts/remote-ssh-home-computer/"><span class="li iconfont icon-article"></span>Cloud is not free, Wakeup and SSH to your home computer remotely</a></p></section></div></section><section id="footer"><div class="footer-wrap">
    <p class="copyright">Â©2020 Ryan Ma</p>
    <p class="powerby"><span>Powered by </span><a href="https://gohugo.io" 
        target="_blank">Hugo</a><span> and the </span><a href="https://themes.gohugo.io/hugo-notepadium/" 
        target="_blank">Notepadium</a></p>
</div></section><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css" integrity="sha384-zB1R0rpPzHqg7Kpt0Aljp8JPLqbXI3bhnPWROx27a9N0Ll6ZP/&#43;DiW/UqRcLbRjq" crossorigin="anonymous"><script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js" integrity="sha384-y23I5Q6l&#43;B6vatafAwxRu/0oK/79VlbSz7Q9aiSZUvyWYIYsd&#43;qj&#43;o24G5ZU2zJz" crossorigin="anonymous"></script><script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js" integrity="sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI" crossorigin="anonymous"
            onload="renderMathInElement(document.body);"></script><script src="/js/prism.min.28f2bfd6dfaa7ad0e8b973373bb7db234d27a2faafc26d5ffd2de4c2b1b5f2bf80011f2e2976dc9fb364abb13f63ebdc.js" integrity="sha384-KPK/1t&#43;qetDouXM3O7fbI00novqvwm1f/S3kwrG18r&#43;AAR8uKXbcn7Nkq7E/Y&#43;vc"></script>
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
	ga('create', 'UA-73966605-1', 'auto');
	
	ga('send', 'pageview');
}
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>
</body>

</html>