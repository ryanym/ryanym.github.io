<!DOCTYPE html>
<html lang="en"><meta charset="utf-8"><meta name="generator" content="Hugo 0.62.0" /><meta name="viewport" content="width=device-width,initial-scale=1,viewport-fit=cover">
<meta name="color-scheme" content="light dark">
<meta name="supported-color-schemes" content="light dark"><title>Paper Study - Weight Agnostic Neural Networks&nbsp;&ndash;&nbsp;Untitled Thoughts</title><link rel="stylesheet" href="/css/core.min.9cb92fcbd3399aceff8fba9449608bf7f45a26e00aea75f0e5bd184f023ca9e14d844a7efefc3e68aa0613112986c902.css" integrity="sha384-nLkvy9M5ms7/j7qUSWCL9/RaJuAK6nXw5b0YTwI8qeFNhEp&#43;/vw&#43;aKoGExEphskC"><meta name="twitter:card" content="summary" />
<meta name="twitter:title" content="Paper Study - Weight Agnostic Neural Networks" />

<link rel="shortcut icon" type="image/x-icon" href="https://ryanym.com/favicon.ico">
<body><section id="header">
    <div class="header wrap"><span class="header left-side"><a class="site home" href="/"><span class="site name">Untitled Thoughts</span></a></span>
        <span class="header right-side"><div class="nav wrap"><nav class="nav"><a class="nav item" href="/categories/">Categories</a><a class="nav item" href="/tags/">Tags</a><a class="nav item" href="/coursework">Coursework</a><a class="nav item" href="/bookshelf/">Bookshelf</a></nav></div></span></div></section><section id="content"><div class="article-container"><section class="article header">
    <h1 class="article title">Paper Study - Weight Agnostic Neural Networks</h1><p class="article date">Thursday, February 11, 2021</p></section><article class="article markdown-body"><p>Interactive version of this paper: <a href="https://weightagnostic.github.io/"target="_blank" rel="noopener noreferrer">https://weightagnostic.github.io/</a>
</p>
<h2 id="summary">Summary</h2>
<p>In a traditional deep learning framework we optimize weights of a fixed network to find the best model. In comparison, for Weight Agnostic Neural Networks (WANNs), we instead search for the best network architecture that perform well over a range of shared weights. The best network architecture usually has strong inductive biases which means importance of weights is minimized. This similar to precocial behaviours in nature.</p>
<p>In order to find the minimal description length WANN, the following steps are performed:</p>
<ol>
<li>Initialize a minimal network and assign a single shared weight parameter to every network connection</li>
<li>Evaluate the network on a wide range of this single weight parameter</li>
<li>Rank the networks by performance and complexity</li>
<li>Create new population by mutate the best networks similar to genetic algorithms</li>
</ol>
<p>Using this technique, WANNs have great representational power to model any function. Which means with enough training we can eventually find the network with the best inductive bias.</p>
<p>WANNs are well suited for RL tasks where the input dimension is low which allows WANNs to encode the relationships between the inputs and the internal states. The performance is on-par with fixed topology with trained weights.</p>
<p>Ensemble and tuned WANNs also perform well with classification problems compare to single layer network with trained weights. The resulting network still maintain the flexibility to allow weight training.</p>
<p>Individual weight in WANNs can also be further turned as offsets from the best shared weight.</p>
<h2 id="critique">Critique</h2>
<ol>
<li>Authors mentioned WANNs are great for models with small input dimensions in some RL settings. However, the they didn’t address the performance of WANNs for more complexed RL problems.</li>
<li>I think the authors did not mention how to vary the network architecture from iteration to iteration. For example, when to add node and when to use a different activation function. What are the parameters to the “neighbour” function.</li>
<li>It seems the underlying assumption is that WANNs will find a network architecture with strong inductive bias with enough training. However, the authors did not benchmark how much training is needed to generate such network.</li>
</ol>
</article><section class="article labels"><a class="category" href=/categories/machine-learning/>machine learning</a><a class="tag" href=/tags/paper/>paper</a><a class="tag" href=/tags/deep-learning/>deep learning</a></section>
</div>
<div class="article bottom"><section class="article navigation"><p><a class="link" href="/posts/paper-study-autodropout/"><span class="iconfont icon-article"></span>Paper Study - AutoDropout: Learning Dropout Patterns to Regularize Deep Networks</a></p><p><a class="link" href="/posts/ctci-on-leetcode/"><span class="iconfont icon-article"></span>Cracking the Coding Interview questions on Leetcode</a></p></section></div></section><section id="footer"><div class="footer-wrap">
    <p class="copyright">©2020 Ryan Ma</p>
    <p class="powerby"><span>Powered&nbsp;by&nbsp;</span><a href="https://gohugo.io" 
        target="_blank" rel="noopener noreferrer">Hugo</a><span>&nbsp;&amp;&nbsp;</span><a href="https://themes.gohugo.io/hugo-notepadium/" 
        target="_blank" rel="noopener noreferrer">Notepadium</a></p></div>
</section><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css" integrity="sha384-zB1R0rpPzHqg7Kpt0Aljp8JPLqbXI3bhnPWROx27a9N0Ll6ZP/&#43;DiW/UqRcLbRjq" crossorigin="anonymous"><script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js" integrity="sha384-y23I5Q6l&#43;B6vatafAwxRu/0oK/79VlbSz7Q9aiSZUvyWYIYsd&#43;qj&#43;o24G5ZU2zJz" crossorigin="anonymous"></script><script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js" integrity="sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI" crossorigin="anonymous"
            onload="renderMathInElement(document.body);"></script><script src="/js/prism.min.28f2bfd6dfaa7ad0e8b973373bb7db234d27a2faafc26d5ffd2de4c2b1b5f2bf80011f2e2976dc9fb364abb13f63ebdc.js" integrity="sha384-KPK/1t&#43;qetDouXM3O7fbI00novqvwm1f/S3kwrG18r&#43;AAR8uKXbcn7Nkq7E/Y&#43;vc"></script>
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
	ga('create', 'UA-73966605-1', 'auto');
	
	ga('send', 'pageview');
}
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>
</body>

</html>