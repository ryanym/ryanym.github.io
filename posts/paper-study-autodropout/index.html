<!DOCTYPE html>
<html lang="en"><meta charset="utf-8"><meta name="generator" content="Hugo 0.62.0" /><meta name="viewport" content="width=device-width,initial-scale=1,viewport-fit=cover">
<meta name="color-scheme" content="light dark">
<meta name="supported-color-schemes" content="light dark"><title>Paper Study - AutoDropout: Learning Dropout Patterns to Regularize Deep Networks&nbsp;&ndash;&nbsp;Untitled Thoughts</title><link rel="stylesheet" href="/css/core.min.9cb92fcbd3399aceff8fba9449608bf7f45a26e00aea75f0e5bd184f023ca9e14d844a7efefc3e68aa0613112986c902.css" integrity="sha384-nLkvy9M5ms7/j7qUSWCL9/RaJuAK6nXw5b0YTwI8qeFNhEp&#43;/vw&#43;aKoGExEphskC"><meta name="twitter:card" content="summary" />
<meta name="twitter:title" content="Paper Study - AutoDropout: Learning Dropout Patterns to Regularize Deep Networks" />

<link rel="shortcut icon" type="image/x-icon" href="https://ryanym.com/favicon.ico">
<body><section id="header">
    <div class="header wrap"><span class="header left-side"><a class="site home" href="/"><span class="site name">Untitled Thoughts</span></a></span>
        <span class="header right-side"><div class="nav wrap"><nav class="nav"><a class="nav item" href="/categories/">Categories</a><a class="nav item" href="/tags/">Tags</a><a class="nav item" href="/coursework">Coursework</a><a class="nav item" href="/bookshelf/">Bookshelf</a></nav></div></span></div></section><section id="content"><div class="article-container"><section class="article header">
    <h1 class="article title">Paper Study - AutoDropout: Learning Dropout Patterns to Regularize Deep Networks</h1><p class="article date">Saturday, February 13, 2021</p></section><article class="article markdown-body"><p>Original paper can be found here: <a href="https://arxiv.org/abs/2101.01761">https://arxiv.org/abs/2101.01761</a></p>
<h2 id="summary"><strong>Summary</strong></h2>
<p>Neural Networks uses regularization methods like Dropout and weight decay to counter over-fitting issues. Recent researches shown that structures of the network can be leveraged to design dropout patterns that achieves better results than randomly dropout.</p>
<p>In practice, dropout patterns are difficult to generalize since they are often task or domain specific.Thus the authors proposed AutoDropout to automate the design of dropout patterns which can be generalized for different applications. AutoDropout leverages reinforcement learning to find the best dropout pattern over a structured search space, where the reward for the RL is the validation performance of the dropout pattern.</p>
<p>Search space for dropout patterns in ConvNets is based on a contiguous, tiled, rectangle, the hyper-parameters includes height, width, stride and repeats. In addition, geometric transformations including rotating and shearing are also added to the search space. Search space for dropout patterns in Transformers is similar. Dropout pattern is realized by four hyper-parameters: size, stride, type of noise mask, how many token does a pattern affects. Unlike ConvNets, dropout pattern can be applied to multiple sublayers in Transformer.</p>
<p>Experiments showed that for supervised and semi-supervised image classification tasks, AutoDropout outperforms SOTA methods, including methods that requires manual dropout pattern design.For Transformers, AutoDropout outperforms Transformer-XL which leverages Variational Dropout.</p>
<h2 id="critique"><strong>Critique</strong></h2>
<ol>
<li>For both ConvNets and Transformers the authors proposed a fixed set of hyper-parameters as the search space. However I don’t think they addressed how these hyper-parameter was selected. If they are selected manually based from empirical experiences, then AutoDropout really isn’t much different from applying optimization on a set of manually selected features.</li>
<li>Authors mentioned that the training cost of AutoDropout could be high because it’s based on RL, however, they did not benchmark any training cost compared to the existing methods.</li>
<li>Authors only briefly mentioned RL is used as the search method even though the core component of AutoDropout is RL. I hope they can explain in detail what are the actions, states and why RL is best suited for this task.</li>
</ol>
</article><section class="article labels"><a class="category" href=/categories/machine-learning/>machine learning</a><a class="tag" href=/tags/paper/>paper</a><a class="tag" href=/tags/deep-learning/>deep learning</a></section>
</div>
<div class="article bottom"><section class="article navigation"><p><a class="link" href="/posts/paper-study-weight-agnostic-neural-networks/"><span class="iconfont icon-article"></span>Paper Study - Weight Agnostic Neural Networks</a></p></section></div></section><section id="footer"><div class="footer-wrap">
    <p class="copyright">©2020 Ryan Ma</p>
    <p class="powerby"><span>Powered&nbsp;by&nbsp;</span><a href="https://gohugo.io" 
        target="_blank" rel="noopener noreferrer">Hugo</a><span>&nbsp;&amp;&nbsp;</span><a href="https://themes.gohugo.io/hugo-notepadium/" 
        target="_blank" rel="noopener noreferrer">Notepadium</a></p></div>
</section><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css" integrity="sha384-zB1R0rpPzHqg7Kpt0Aljp8JPLqbXI3bhnPWROx27a9N0Ll6ZP/&#43;DiW/UqRcLbRjq" crossorigin="anonymous"><script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js" integrity="sha384-y23I5Q6l&#43;B6vatafAwxRu/0oK/79VlbSz7Q9aiSZUvyWYIYsd&#43;qj&#43;o24G5ZU2zJz" crossorigin="anonymous"></script><script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js" integrity="sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI" crossorigin="anonymous"
            onload="renderMathInElement(document.body);"></script><script src="/js/prism.min.28f2bfd6dfaa7ad0e8b973373bb7db234d27a2faafc26d5ffd2de4c2b1b5f2bf80011f2e2976dc9fb364abb13f63ebdc.js" integrity="sha384-KPK/1t&#43;qetDouXM3O7fbI00novqvwm1f/S3kwrG18r&#43;AAR8uKXbcn7Nkq7E/Y&#43;vc"></script>
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
	ga('create', 'UA-73966605-1', 'auto');
	
	ga('send', 'pageview');
}
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>
</body>

</html>