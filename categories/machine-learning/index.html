<!DOCTYPE html>
<html lang="en"><meta charset="utf-8"><meta name="generator" content="Hugo 0.62.0" /><meta name="viewport" content="width=device-width,initial-scale=1,viewport-fit=cover">
<meta name="color-scheme" content="light dark">
<meta name="supported-color-schemes" content="light dark"><title>machine learning&nbsp;&ndash;&nbsp;Untitled Thoughts</title><link rel="stylesheet" href="/css/core.min.9cb92fcbd3399aceff8fba9449608bf7f45a26e00aea75f0e5bd184f023ca9e14d844a7efefc3e68aa0613112986c902.css" integrity="sha384-nLkvy9M5ms7/j7qUSWCL9/RaJuAK6nXw5b0YTwI8qeFNhEp&#43;/vw&#43;aKoGExEphskC"><link rel="alternate" type="application/rss+xml" href="/categories/machine-learning/index.xml" title="Untitled Thoughts" /><meta name="twitter:card" content="summary" />
<meta name="twitter:title" content="machine learning" />

<link rel="shortcut icon" type="image/x-icon" href="https://ryanym.com/favicon.ico">
<body><section id="header">
    <div class="header wrap"><span class="header left-side"><a class="site home" href="/"><span class="site name">Untitled Thoughts</span></a></span>
        <span class="header right-side"><div class="nav wrap"><nav class="nav"><a class="nav item" href="/categories/">Categories</a><a class="nav item" href="/tags/">Tags</a><a class="nav item" href="/coursework">Coursework</a><a class="nav item" href="/bookshelf/">Bookshelf</a></nav></div></span></div></section><section id="content"><section class="article header"><h1>machine learning</h1></section><ul class="note list"><li class="item"><a class="note" href="/posts/paper-study-autodropout/">
            <p class="note title">Paper Study - AutoDropout: Learning Dropout Patterns to Regularize Deep Networks</p><p class="note date">Saturday, February 13, 2021</p><p class="note content">Original paper can be found here: https://arxiv.org/abs/2101.01761
Summary Neural Networks uses regularization methods like Dropout and weight decay to counter over-fitting issues. Recent researches shown that structures of the network can be leveraged to design dropout patterns that achieves better results than randomly dropout.
In practice, dropout patterns are difficult to generalize since they are often task or domain specific.Thus the authors proposed AutoDropout to automate the design of dropout patterns which can be generalized for different applications.<span class="mldr">&mldr;</span></p></a><p class="note labels"><a class="category" href="/categories/machine-learning/">machine learning</a><a class="tag" href="/tags/paper/">paper</a><a class="tag" href="/tags/deep-learning/">deep learning</a></p></li><li class="item"><a class="note" href="/posts/paper-study-weight-agnostic-neural-networks/">
            <p class="note title">Paper Study - Weight Agnostic Neural Networks</p><p class="note date">Thursday, February 11, 2021</p><p class="note content">Interactive version of this paper: https://weightagnostic.github.io/ Summary In a traditional deep learning framework we optimize weights of a fixed network to find the best model. In comparison, for Weight Agnostic Neural Networks (WANNs), we instead search for the best network architecture that perform well over a range of shared weights. The best network architecture usually has strong inductive biases which means importance of weights is minimized. This similar to precocial behaviours in nature.<span class="mldr">&mldr;</span></p></a><p class="note labels"><a class="category" href="/categories/machine-learning/">machine learning</a><a class="tag" href="/tags/paper/">paper</a><a class="tag" href="/tags/deep-learning/">deep learning</a></p></li></ul></section><section id="footer"><div class="footer-wrap">
    <p class="copyright">Â©2020 Ryan Ma</p>
    <p class="powerby"><span>Powered&nbsp;by&nbsp;</span><a href="https://gohugo.io" 
        target="_blank" rel="noopener noreferrer">Hugo</a><span>&nbsp;&amp;&nbsp;</span><a href="https://themes.gohugo.io/hugo-notepadium/" 
        target="_blank" rel="noopener noreferrer">Notepadium</a></p></div>
</section><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css" integrity="sha384-zB1R0rpPzHqg7Kpt0Aljp8JPLqbXI3bhnPWROx27a9N0Ll6ZP/&#43;DiW/UqRcLbRjq" crossorigin="anonymous"><script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js" integrity="sha384-y23I5Q6l&#43;B6vatafAwxRu/0oK/79VlbSz7Q9aiSZUvyWYIYsd&#43;qj&#43;o24G5ZU2zJz" crossorigin="anonymous"></script><script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js" integrity="sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI" crossorigin="anonymous"
            onload="renderMathInElement(document.body);"></script><script src="/js/prism.min.28f2bfd6dfaa7ad0e8b973373bb7db234d27a2faafc26d5ffd2de4c2b1b5f2bf80011f2e2976dc9fb364abb13f63ebdc.js" integrity="sha384-KPK/1t&#43;qetDouXM3O7fbI00novqvwm1f/S3kwrG18r&#43;AAR8uKXbcn7Nkq7E/Y&#43;vc"></script>
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
	ga('create', 'UA-73966605-1', 'auto');
	
	ga('send', 'pageview');
}
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>
</body>

</html>