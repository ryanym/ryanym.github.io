<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>hadoop on Untitled Thoughts</title>
    <link>/tags/hadoop/</link>
    <description>Recent content in hadoop on Untitled Thoughts</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <copyright>Â©2020 Ryan Ma</copyright>
    <lastBuildDate>Wed, 05 Feb 2020 22:26:04 -0500</lastBuildDate>
    
        <atom:link href="/tags/hadoop/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Accessing mutiple Hadoop amespaces with native HDFS client</title>
      <link>/posts/hadoop-multi-namespaces/</link>
      <pubDate>Wed, 05 Feb 2020 22:26:04 -0500</pubDate>
      
      <guid>/posts/hadoop-multi-namespaces/</guid>
      <description>In hadoop we can have multiple namespaces in hdfs-site.xml for HDFS clients. This is achieved by a HDFS feature called: HDFS Federation
Why do you need multiple namespaces This feature is particularly useful when you need to distcp data between multiple highly available remote hadoop clusters. For HA clusters we don&#39;t always know the address of active namenode and it&#39;s not recommanded to hardcode the active namenode address in the distcp command in case of namenode fail over.</description>
      
    </item>
    
  </channel>
</rss>
